# Program 2 - Tokenization

This program will identify and remove comments from an input test file using a deterministic finite state automoton (DFA) before using a DFA to convert the input file into a series of tokens.

Authored by: Blake Marshall, Brandon Robinson, Holden Ea, Rolando Yax, and Jacob Sellers

## Running the program: 

This project can be run via make.

```make```

```./tokenize.x```

If you have a Windows based machine, you will need to adjust the Makefile to generate an ```.exe``` executable, rather than ```.x```.
